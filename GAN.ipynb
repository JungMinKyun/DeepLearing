{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a26af4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp311-cp311-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.0.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchvision) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe295d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4391fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "\n",
    "# 생성자(Generator) 클래스 정의\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # 하나의 블록(block) 정의\n",
    "        def block(input_dim, output_dim, normalize=True):\n",
    "            layers = [nn.Linear(input_dim, output_dim)]\n",
    "            if normalize:\n",
    "                # 배치 정규화(batch normalization) 수행(차원 동일)\n",
    "                layers.append(nn.BatchNorm1d(output_dim, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        # 생성자 모델은 연속적인 여러 개의 블록을 가짐\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, 1 * 28 * 28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 1, 28, 28)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e156bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자(Discriminator) 클래스 정의\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1 * 28 * 28, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    # 이미지에 대한 판별 결과를 반환\n",
    "    def forward(self, img):\n",
    "        flattened = img.view(img.size(0), -1)\n",
    "        output = self.model(flattened)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76a633f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 9912422/9912422 [00:02<00:00, 4150292.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/train-images-idx3-ubyte.gz to ./dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 28881/28881 [00:00<00:00, 7309660.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/train-labels-idx1-ubyte.gz to ./dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1648877/1648877 [00:00<00:00, 2513196.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to ./dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 4542/4542 [00:00<00:00, 4710813.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./dataset/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./dataset\", train=True, download=True, transform=transforms_train)\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad9396e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is MPS (Metal Performance Shader) built? True\n",
      "Is MPS available? True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f17494c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자(generator)와 판별자(discriminator) 초기화\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "# 손실 함수(loss function)\n",
    "adversarial_loss = nn.BCELoss()\n",
    "adversarial_loss.to(device)\n",
    "\n",
    "# 학습률(learning rate) 설정\n",
    "lr = 0.0002\n",
    "\n",
    "# 생성자와 판별자를 위한 최적화 함수\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e60cc5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [D loss: 0.630109] [G loss: 1.249236] [Elapsed time: 12.21s]\n",
      "[Epoch 1/200] [D loss: 0.545815] [G loss: 1.076102] [Elapsed time: 20.23s]\n",
      "[Epoch 2/200] [D loss: 0.305982] [G loss: 1.025658] [Elapsed time: 28.42s]\n",
      "[Epoch 3/200] [D loss: 0.478528] [G loss: 0.579132] [Elapsed time: 36.63s]\n",
      "[Epoch 4/200] [D loss: 0.386330] [G loss: 0.832298] [Elapsed time: 45.05s]\n",
      "[Epoch 5/200] [D loss: 0.434137] [G loss: 2.870917] [Elapsed time: 53.17s]\n",
      "[Epoch 6/200] [D loss: 0.321214] [G loss: 0.953051] [Elapsed time: 61.49s]\n",
      "[Epoch 7/200] [D loss: 0.188765] [G loss: 1.331848] [Elapsed time: 69.62s]\n",
      "[Epoch 8/200] [D loss: 0.254302] [G loss: 1.236022] [Elapsed time: 77.84s]\n",
      "[Epoch 9/200] [D loss: 0.258140] [G loss: 1.361077] [Elapsed time: 85.76s]\n",
      "[Epoch 10/200] [D loss: 0.204036] [G loss: 2.583366] [Elapsed time: 93.71s]\n",
      "[Epoch 11/200] [D loss: 0.309825] [G loss: 1.095897] [Elapsed time: 101.64s]\n",
      "[Epoch 12/200] [D loss: 0.181582] [G loss: 1.764064] [Elapsed time: 109.77s]\n",
      "[Epoch 13/200] [D loss: 0.214277] [G loss: 1.328714] [Elapsed time: 117.79s]\n",
      "[Epoch 14/200] [D loss: 0.162019] [G loss: 1.744892] [Elapsed time: 126.05s]\n",
      "[Epoch 15/200] [D loss: 0.142007] [G loss: 1.713875] [Elapsed time: 134.37s]\n",
      "[Epoch 16/200] [D loss: 0.130518] [G loss: 2.441854] [Elapsed time: 142.60s]\n",
      "[Epoch 17/200] [D loss: 0.452973] [G loss: 6.009601] [Elapsed time: 150.85s]\n",
      "[Epoch 18/200] [D loss: 0.629958] [G loss: 5.715419] [Elapsed time: 159.00s]\n",
      "[Epoch 19/200] [D loss: 0.188582] [G loss: 1.993012] [Elapsed time: 167.13s]\n",
      "[Epoch 20/200] [D loss: 0.549004] [G loss: 0.656033] [Elapsed time: 175.39s]\n",
      "[Epoch 21/200] [D loss: 0.205352] [G loss: 2.411962] [Elapsed time: 183.68s]\n",
      "[Epoch 22/200] [D loss: 0.235429] [G loss: 2.147761] [Elapsed time: 191.94s]\n",
      "[Epoch 23/200] [D loss: 0.289067] [G loss: 2.549437] [Elapsed time: 200.21s]\n",
      "[Epoch 24/200] [D loss: 0.296515] [G loss: 2.076550] [Elapsed time: 208.41s]\n",
      "[Epoch 25/200] [D loss: 0.230390] [G loss: 1.668411] [Elapsed time: 216.68s]\n",
      "[Epoch 26/200] [D loss: 0.330649] [G loss: 1.352721] [Elapsed time: 224.98s]\n",
      "[Epoch 27/200] [D loss: 0.167226] [G loss: 2.251740] [Elapsed time: 233.23s]\n",
      "[Epoch 28/200] [D loss: 0.273474] [G loss: 2.021838] [Elapsed time: 241.49s]\n",
      "[Epoch 29/200] [D loss: 0.276159] [G loss: 3.245422] [Elapsed time: 249.78s]\n",
      "[Epoch 30/200] [D loss: 0.231016] [G loss: 2.311654] [Elapsed time: 258.01s]\n",
      "[Epoch 31/200] [D loss: 0.552325] [G loss: 5.365930] [Elapsed time: 266.29s]\n",
      "[Epoch 32/200] [D loss: 0.328833] [G loss: 1.464318] [Elapsed time: 274.57s]\n",
      "[Epoch 33/200] [D loss: 0.284949] [G loss: 1.288542] [Elapsed time: 282.84s]\n",
      "[Epoch 34/200] [D loss: 0.242389] [G loss: 1.919062] [Elapsed time: 291.06s]\n",
      "[Epoch 35/200] [D loss: 0.237277] [G loss: 2.234771] [Elapsed time: 299.29s]\n",
      "[Epoch 36/200] [D loss: 0.515423] [G loss: 0.856661] [Elapsed time: 307.58s]\n",
      "[Epoch 37/200] [D loss: 0.214807] [G loss: 2.803167] [Elapsed time: 315.85s]\n",
      "[Epoch 38/200] [D loss: 0.199880] [G loss: 2.586068] [Elapsed time: 324.13s]\n",
      "[Epoch 39/200] [D loss: 0.309130] [G loss: 4.348979] [Elapsed time: 332.42s]\n",
      "[Epoch 40/200] [D loss: 0.258389] [G loss: 2.766677] [Elapsed time: 340.73s]\n",
      "[Epoch 41/200] [D loss: 0.235346] [G loss: 1.806540] [Elapsed time: 349.00s]\n",
      "[Epoch 42/200] [D loss: 0.190671] [G loss: 1.962194] [Elapsed time: 357.36s]\n",
      "[Epoch 43/200] [D loss: 0.362000] [G loss: 3.475224] [Elapsed time: 365.74s]\n",
      "[Epoch 44/200] [D loss: 0.267319] [G loss: 2.311380] [Elapsed time: 374.05s]\n",
      "[Epoch 45/200] [D loss: 0.279067] [G loss: 2.819984] [Elapsed time: 382.37s]\n",
      "[Epoch 46/200] [D loss: 0.226614] [G loss: 2.316405] [Elapsed time: 390.69s]\n",
      "[Epoch 47/200] [D loss: 0.291166] [G loss: 2.956514] [Elapsed time: 398.99s]\n",
      "[Epoch 48/200] [D loss: 0.207008] [G loss: 1.859826] [Elapsed time: 407.35s]\n",
      "[Epoch 49/200] [D loss: 0.205891] [G loss: 2.564924] [Elapsed time: 415.77s]\n",
      "[Epoch 50/200] [D loss: 0.265868] [G loss: 1.648165] [Elapsed time: 424.28s]\n",
      "[Epoch 51/200] [D loss: 0.192156] [G loss: 3.606089] [Elapsed time: 432.90s]\n",
      "[Epoch 52/200] [D loss: 0.278823] [G loss: 2.633702] [Elapsed time: 441.45s]\n",
      "[Epoch 53/200] [D loss: 0.287993] [G loss: 2.719769] [Elapsed time: 449.97s]\n",
      "[Epoch 54/200] [D loss: 0.335841] [G loss: 3.541877] [Elapsed time: 458.53s]\n",
      "[Epoch 55/200] [D loss: 0.324771] [G loss: 1.181434] [Elapsed time: 467.07s]\n",
      "[Epoch 56/200] [D loss: 0.282717] [G loss: 2.232529] [Elapsed time: 475.35s]\n",
      "[Epoch 57/200] [D loss: 0.315903] [G loss: 2.884865] [Elapsed time: 483.63s]\n",
      "[Epoch 58/200] [D loss: 0.269616] [G loss: 1.650263] [Elapsed time: 491.89s]\n",
      "[Epoch 59/200] [D loss: 0.325886] [G loss: 1.158640] [Elapsed time: 500.22s]\n",
      "[Epoch 60/200] [D loss: 0.185794] [G loss: 2.011166] [Elapsed time: 508.49s]\n",
      "[Epoch 61/200] [D loss: 0.206042] [G loss: 3.123742] [Elapsed time: 516.93s]\n",
      "[Epoch 62/200] [D loss: 0.380161] [G loss: 1.218601] [Elapsed time: 525.26s]\n",
      "[Epoch 63/200] [D loss: 0.253402] [G loss: 3.102469] [Elapsed time: 533.57s]\n",
      "[Epoch 64/200] [D loss: 0.245309] [G loss: 4.256094] [Elapsed time: 541.88s]\n",
      "[Epoch 65/200] [D loss: 0.297330] [G loss: 1.282187] [Elapsed time: 550.26s]\n",
      "[Epoch 66/200] [D loss: 0.178179] [G loss: 1.893451] [Elapsed time: 558.61s]\n",
      "[Epoch 67/200] [D loss: 0.238050] [G loss: 3.440021] [Elapsed time: 566.88s]\n",
      "[Epoch 68/200] [D loss: 0.277014] [G loss: 1.843908] [Elapsed time: 575.16s]\n",
      "[Epoch 69/200] [D loss: 0.223958] [G loss: 2.081983] [Elapsed time: 583.45s]\n",
      "[Epoch 70/200] [D loss: 0.153186] [G loss: 3.174873] [Elapsed time: 591.82s]\n",
      "[Epoch 71/200] [D loss: 0.306138] [G loss: 1.597509] [Elapsed time: 600.17s]\n",
      "[Epoch 72/200] [D loss: 0.172383] [G loss: 2.785233] [Elapsed time: 608.52s]\n",
      "[Epoch 73/200] [D loss: 0.262959] [G loss: 1.975916] [Elapsed time: 616.84s]\n",
      "[Epoch 74/200] [D loss: 0.151612] [G loss: 3.325867] [Elapsed time: 625.22s]\n",
      "[Epoch 75/200] [D loss: 0.286533] [G loss: 1.642587] [Elapsed time: 633.59s]\n",
      "[Epoch 76/200] [D loss: 0.110871] [G loss: 2.362576] [Elapsed time: 641.96s]\n",
      "[Epoch 77/200] [D loss: 0.163981] [G loss: 2.756273] [Elapsed time: 650.28s]\n",
      "[Epoch 78/200] [D loss: 0.329999] [G loss: 3.825015] [Elapsed time: 658.59s]\n",
      "[Epoch 79/200] [D loss: 0.257309] [G loss: 2.389141] [Elapsed time: 666.91s]\n",
      "[Epoch 80/200] [D loss: 0.153441] [G loss: 2.169522] [Elapsed time: 675.38s]\n",
      "[Epoch 81/200] [D loss: 0.166066] [G loss: 4.935378] [Elapsed time: 683.96s]\n",
      "[Epoch 82/200] [D loss: 0.128557] [G loss: 3.325357] [Elapsed time: 692.35s]\n",
      "[Epoch 83/200] [D loss: 0.143990] [G loss: 3.357128] [Elapsed time: 700.75s]\n",
      "[Epoch 84/200] [D loss: 0.168337] [G loss: 2.678096] [Elapsed time: 709.17s]\n",
      "[Epoch 85/200] [D loss: 0.273345] [G loss: 1.513654] [Elapsed time: 717.48s]\n",
      "[Epoch 86/200] [D loss: 0.207703] [G loss: 2.106250] [Elapsed time: 725.86s]\n",
      "[Epoch 87/200] [D loss: 0.244758] [G loss: 1.608367] [Elapsed time: 734.35s]\n",
      "[Epoch 88/200] [D loss: 0.177189] [G loss: 2.117335] [Elapsed time: 742.63s]\n",
      "[Epoch 89/200] [D loss: 0.177083] [G loss: 2.086112] [Elapsed time: 750.91s]\n",
      "[Epoch 90/200] [D loss: 0.177840] [G loss: 2.531906] [Elapsed time: 759.17s]\n",
      "[Epoch 91/200] [D loss: 0.167146] [G loss: 2.681756] [Elapsed time: 767.41s]\n",
      "[Epoch 92/200] [D loss: 0.217076] [G loss: 2.563670] [Elapsed time: 775.66s]\n",
      "[Epoch 93/200] [D loss: 0.213964] [G loss: 1.541325] [Elapsed time: 783.98s]\n",
      "[Epoch 94/200] [D loss: 0.218718] [G loss: 1.919888] [Elapsed time: 792.25s]\n",
      "[Epoch 95/200] [D loss: 0.238295] [G loss: 1.856583] [Elapsed time: 800.57s]\n",
      "[Epoch 96/200] [D loss: 0.273170] [G loss: 2.063687] [Elapsed time: 808.97s]\n",
      "[Epoch 97/200] [D loss: 0.255779] [G loss: 3.054401] [Elapsed time: 817.27s]\n",
      "[Epoch 98/200] [D loss: 0.213175] [G loss: 2.295581] [Elapsed time: 825.55s]\n",
      "[Epoch 99/200] [D loss: 0.283719] [G loss: 1.687637] [Elapsed time: 834.01s]\n",
      "[Epoch 100/200] [D loss: 0.176245] [G loss: 2.290493] [Elapsed time: 842.32s]\n",
      "[Epoch 101/200] [D loss: 0.229420] [G loss: 2.215028] [Elapsed time: 850.63s]\n",
      "[Epoch 102/200] [D loss: 0.361314] [G loss: 1.440134] [Elapsed time: 858.99s]\n",
      "[Epoch 103/200] [D loss: 0.195092] [G loss: 3.114864] [Elapsed time: 867.55s]\n",
      "[Epoch 104/200] [D loss: 0.259591] [G loss: 2.081369] [Elapsed time: 876.16s]\n",
      "[Epoch 105/200] [D loss: 0.272583] [G loss: 2.092951] [Elapsed time: 884.68s]\n",
      "[Epoch 106/200] [D loss: 0.251568] [G loss: 1.745854] [Elapsed time: 893.22s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 107/200] [D loss: 0.224929] [G loss: 2.259154] [Elapsed time: 901.59s]\n",
      "[Epoch 108/200] [D loss: 0.329900] [G loss: 1.920098] [Elapsed time: 909.94s]\n",
      "[Epoch 109/200] [D loss: 0.292466] [G loss: 1.181937] [Elapsed time: 918.25s]\n",
      "[Epoch 110/200] [D loss: 0.335024] [G loss: 1.939206] [Elapsed time: 926.79s]\n",
      "[Epoch 111/200] [D loss: 0.469636] [G loss: 3.519114] [Elapsed time: 935.27s]\n",
      "[Epoch 112/200] [D loss: 0.258243] [G loss: 2.807069] [Elapsed time: 943.59s]\n",
      "[Epoch 113/200] [D loss: 0.390385] [G loss: 1.171601] [Elapsed time: 951.90s]\n",
      "[Epoch 114/200] [D loss: 0.339822] [G loss: 1.212846] [Elapsed time: 960.25s]\n",
      "[Epoch 115/200] [D loss: 0.273361] [G loss: 1.599230] [Elapsed time: 968.59s]\n",
      "[Epoch 116/200] [D loss: 0.302177] [G loss: 1.768785] [Elapsed time: 977.02s]\n",
      "[Epoch 117/200] [D loss: 0.318431] [G loss: 2.230555] [Elapsed time: 985.37s]\n",
      "[Epoch 118/200] [D loss: 0.296209] [G loss: 2.286486] [Elapsed time: 993.98s]\n",
      "[Epoch 119/200] [D loss: 0.294064] [G loss: 4.696929] [Elapsed time: 1002.33s]\n",
      "[Epoch 120/200] [D loss: 0.231331] [G loss: 2.156002] [Elapsed time: 1010.69s]\n",
      "[Epoch 121/200] [D loss: 0.256025] [G loss: 3.603997] [Elapsed time: 1019.08s]\n",
      "[Epoch 122/200] [D loss: 0.355459] [G loss: 1.235330] [Elapsed time: 1027.42s]\n",
      "[Epoch 123/200] [D loss: 0.347682] [G loss: 1.849973] [Elapsed time: 1036.06s]\n",
      "[Epoch 124/200] [D loss: 0.233223] [G loss: 1.822551] [Elapsed time: 1044.40s]\n",
      "[Epoch 125/200] [D loss: 0.361288] [G loss: 3.442696] [Elapsed time: 1052.72s]\n",
      "[Epoch 126/200] [D loss: 0.417316] [G loss: 4.478372] [Elapsed time: 1061.09s]\n",
      "[Epoch 127/200] [D loss: 0.276169] [G loss: 1.594483] [Elapsed time: 1069.46s]\n",
      "[Epoch 128/200] [D loss: 0.343442] [G loss: 2.935946] [Elapsed time: 1077.80s]\n",
      "[Epoch 129/200] [D loss: 0.268479] [G loss: 1.881893] [Elapsed time: 1086.33s]\n",
      "[Epoch 130/200] [D loss: 0.270385] [G loss: 1.682729] [Elapsed time: 1094.91s]\n",
      "[Epoch 131/200] [D loss: 0.253553] [G loss: 2.122566] [Elapsed time: 1103.47s]\n",
      "[Epoch 132/200] [D loss: 0.233126] [G loss: 2.204964] [Elapsed time: 1111.94s]\n",
      "[Epoch 133/200] [D loss: 0.289968] [G loss: 1.652100] [Elapsed time: 1120.29s]\n",
      "[Epoch 134/200] [D loss: 0.241830] [G loss: 2.247079] [Elapsed time: 1128.73s]\n",
      "[Epoch 135/200] [D loss: 0.310381] [G loss: 2.206941] [Elapsed time: 1136.99s]\n",
      "[Epoch 136/200] [D loss: 0.251950] [G loss: 2.365722] [Elapsed time: 1145.35s]\n",
      "[Epoch 137/200] [D loss: 0.314918] [G loss: 2.515201] [Elapsed time: 1153.67s]\n",
      "[Epoch 138/200] [D loss: 0.264873] [G loss: 2.049141] [Elapsed time: 1162.14s]\n",
      "[Epoch 139/200] [D loss: 0.195442] [G loss: 3.062964] [Elapsed time: 1170.52s]\n",
      "[Epoch 140/200] [D loss: 0.301506] [G loss: 2.813740] [Elapsed time: 1178.83s]\n",
      "[Epoch 141/200] [D loss: 0.293014] [G loss: 1.757604] [Elapsed time: 1187.26s]\n",
      "[Epoch 142/200] [D loss: 0.311334] [G loss: 1.598884] [Elapsed time: 1195.73s]\n",
      "[Epoch 143/200] [D loss: 0.322406] [G loss: 4.477486] [Elapsed time: 1204.30s]\n",
      "[Epoch 144/200] [D loss: 0.260417] [G loss: 2.141332] [Elapsed time: 1212.84s]\n",
      "[Epoch 145/200] [D loss: 0.248836] [G loss: 2.265639] [Elapsed time: 1221.04s]\n",
      "[Epoch 146/200] [D loss: 0.266426] [G loss: 1.450705] [Elapsed time: 1229.41s]\n",
      "[Epoch 147/200] [D loss: 0.308664] [G loss: 2.420053] [Elapsed time: 1237.78s]\n",
      "[Epoch 148/200] [D loss: 0.255734] [G loss: 1.961311] [Elapsed time: 1246.12s]\n",
      "[Epoch 149/200] [D loss: 0.308542] [G loss: 2.156645] [Elapsed time: 1254.65s]\n",
      "[Epoch 150/200] [D loss: 0.326666] [G loss: 1.657421] [Elapsed time: 1263.06s]\n",
      "[Epoch 151/200] [D loss: 0.240698] [G loss: 2.346931] [Elapsed time: 1271.46s]\n",
      "[Epoch 152/200] [D loss: 0.220124] [G loss: 1.960034] [Elapsed time: 1279.78s]\n",
      "[Epoch 153/200] [D loss: 0.289115] [G loss: 2.474903] [Elapsed time: 1288.20s]\n",
      "[Epoch 154/200] [D loss: 0.262073] [G loss: 2.030338] [Elapsed time: 1296.54s]\n",
      "[Epoch 155/200] [D loss: 0.245924] [G loss: 2.312618] [Elapsed time: 1304.86s]\n",
      "[Epoch 156/200] [D loss: 0.221194] [G loss: 2.124052] [Elapsed time: 1313.14s]\n",
      "[Epoch 157/200] [D loss: 0.323284] [G loss: 2.639771] [Elapsed time: 1321.72s]\n",
      "[Epoch 158/200] [D loss: 0.205461] [G loss: 2.862161] [Elapsed time: 1330.16s]\n",
      "[Epoch 159/200] [D loss: 0.341931] [G loss: 1.654361] [Elapsed time: 1338.42s]\n",
      "[Epoch 160/200] [D loss: 0.224991] [G loss: 2.346323] [Elapsed time: 1346.79s]\n",
      "[Epoch 161/200] [D loss: 0.229699] [G loss: 2.524538] [Elapsed time: 1355.17s]\n",
      "[Epoch 162/200] [D loss: 0.335375] [G loss: 1.347955] [Elapsed time: 1363.66s]\n",
      "[Epoch 163/200] [D loss: 0.250464] [G loss: 1.775096] [Elapsed time: 1372.15s]\n",
      "[Epoch 164/200] [D loss: 0.266730] [G loss: 2.554706] [Elapsed time: 1380.53s]\n",
      "[Epoch 165/200] [D loss: 0.207745] [G loss: 2.409432] [Elapsed time: 1388.89s]\n",
      "[Epoch 166/200] [D loss: 0.234649] [G loss: 2.610005] [Elapsed time: 1397.23s]\n",
      "[Epoch 167/200] [D loss: 0.296373] [G loss: 2.295396] [Elapsed time: 1405.59s]\n",
      "[Epoch 168/200] [D loss: 0.274077] [G loss: 2.046200] [Elapsed time: 1413.96s]\n",
      "[Epoch 169/200] [D loss: 0.353649] [G loss: 2.158669] [Elapsed time: 1422.40s]\n",
      "[Epoch 170/200] [D loss: 0.248788] [G loss: 2.075806] [Elapsed time: 1430.80s]\n",
      "[Epoch 171/200] [D loss: 0.227389] [G loss: 2.379362] [Elapsed time: 1439.20s]\n",
      "[Epoch 172/200] [D loss: 0.240481] [G loss: 2.085432] [Elapsed time: 1447.60s]\n",
      "[Epoch 173/200] [D loss: 0.305106] [G loss: 2.911109] [Elapsed time: 1456.04s]\n",
      "[Epoch 174/200] [D loss: 0.243843] [G loss: 2.528606] [Elapsed time: 1464.64s]\n",
      "[Epoch 175/200] [D loss: 0.277774] [G loss: 2.323089] [Elapsed time: 1473.09s]\n",
      "[Epoch 176/200] [D loss: 0.247952] [G loss: 2.517628] [Elapsed time: 1481.51s]\n",
      "[Epoch 177/200] [D loss: 0.219606] [G loss: 1.999281] [Elapsed time: 1489.93s]\n",
      "[Epoch 178/200] [D loss: 0.302010] [G loss: 1.925227] [Elapsed time: 1498.36s]\n",
      "[Epoch 179/200] [D loss: 0.291115] [G loss: 1.737892] [Elapsed time: 1507.10s]\n",
      "[Epoch 180/200] [D loss: 0.325060] [G loss: 1.099080] [Elapsed time: 1515.50s]\n",
      "[Epoch 181/200] [D loss: 0.269756] [G loss: 1.378021] [Elapsed time: 1524.11s]\n",
      "[Epoch 182/200] [D loss: 0.283141] [G loss: 2.874461] [Elapsed time: 1532.52s]\n",
      "[Epoch 183/200] [D loss: 0.231985] [G loss: 2.057803] [Elapsed time: 1540.93s]\n",
      "[Epoch 184/200] [D loss: 0.179385] [G loss: 2.255487] [Elapsed time: 1549.27s]\n",
      "[Epoch 185/200] [D loss: 0.273538] [G loss: 2.128435] [Elapsed time: 1557.76s]\n",
      "[Epoch 186/200] [D loss: 0.429969] [G loss: 1.259295] [Elapsed time: 1566.31s]\n",
      "[Epoch 187/200] [D loss: 0.188146] [G loss: 3.075249] [Elapsed time: 1574.82s]\n",
      "[Epoch 188/200] [D loss: 0.217924] [G loss: 2.507651] [Elapsed time: 1583.22s]\n",
      "[Epoch 189/200] [D loss: 0.354480] [G loss: 3.628772] [Elapsed time: 1591.82s]\n",
      "[Epoch 190/200] [D loss: 0.300260] [G loss: 1.732389] [Elapsed time: 1600.35s]\n",
      "[Epoch 191/200] [D loss: 0.196368] [G loss: 2.136287] [Elapsed time: 1608.78s]\n",
      "[Epoch 192/200] [D loss: 0.295757] [G loss: 1.452497] [Elapsed time: 1617.14s]\n",
      "[Epoch 193/200] [D loss: 0.285812] [G loss: 2.039138] [Elapsed time: 1625.43s]\n",
      "[Epoch 194/200] [D loss: 0.257557] [G loss: 2.483508] [Elapsed time: 1633.83s]\n",
      "[Epoch 195/200] [D loss: 0.303073] [G loss: 2.984719] [Elapsed time: 1642.24s]\n",
      "[Epoch 196/200] [D loss: 0.204422] [G loss: 3.036457] [Elapsed time: 1650.65s]\n",
      "[Epoch 197/200] [D loss: 0.404727] [G loss: 2.007809] [Elapsed time: 1658.99s]\n",
      "[Epoch 198/200] [D loss: 0.285864] [G loss: 2.412467] [Elapsed time: 1667.41s]\n",
      "[Epoch 199/200] [D loss: 0.189267] [G loss: 2.237646] [Elapsed time: 1675.84s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 200  # 학습의 횟수(epoch) 설정\n",
    "sample_interval = 2000  # 몇 번의 배치(batch)마다 결과를 출력할 것인지 설정\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # 진짜(real) 이미지와 가짜(fake) 이미지에 대한 정답 레이블 생성\n",
    "        real = torch.FloatTensor(imgs.size(0), 1).fill_(1.0).to(device)  # 진짜(real): 1\n",
    "        fake = torch.FloatTensor(imgs.size(0), 1).fill_(0.0).to(device)  # 가짜(fake): 0\n",
    "\n",
    "        real_imgs = imgs.to(device)\n",
    "\n",
    "        \"\"\" 생성자(generator)를 학습합니다. \"\"\"\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # 랜덤 노이즈(noise) 샘플링\n",
    "        z = torch.normal(mean=0, std=1, size=(imgs.shape[0], latent_dim)).to(device)\n",
    "\n",
    "        # 이미지 생성\n",
    "        generated_imgs = generator(z)\n",
    "\n",
    "        # 생성자(generator)의 손실(loss) 값 계산\n",
    "        g_loss = adversarial_loss(discriminator(generated_imgs), real)\n",
    "\n",
    "        # 생성자(generator) 업데이트\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \"\"\" 판별자(discriminator)를 학습합니다. \"\"\"\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # 판별자(discriminator)의 손실(loss) 값 계산\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), real)\n",
    "        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        # 판별자(discriminator) 업데이트\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        done = epoch * len(dataloader) + i\n",
    "        if done % sample_interval == 0:\n",
    "            # 생성된 이미지 중에서 25개만 선택하여 5 X 5 격자 이미지에 출력\n",
    "            save_image(generated_imgs.data[:25], f\"{done}.png\", nrow=5, normalize=True)\n",
    "\n",
    "    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n",
    "    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [Elapsed time: {time.time() - start_time:.2f}s]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5db72f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('92000.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29839153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
